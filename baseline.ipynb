{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "This is the entrypoint for the competition, it:\n",
    "\n",
    "* Reads data from tweets' CSV files\n",
    "* Computes Bag of Words (BoW) from textual representations (tweets text)\n",
    "* Tests two models to find out which performs better\n",
    "* Predicts classes for the submission/benchmark tweets\n",
    "* Generates a suitable CSV for Kaggle InClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data representation\n",
    "\n",
    "The function `obtain_data_representation` performs the BoW transformation over the training set and applies it to both the train and test set.\n",
    "\n",
    "If no test set is provided, the input DataFrame is split into both train and test, 75% and 25% of the data respectively. This is done so as to be able to obtain an accuracy score, which will be the evaluation metric on Kaggle.\n",
    "\n",
    "BoW is computed through `CountVectorizer` class of `sklearn`, restricting it to at most 200 features. The process of finding the best words is done by the `fit` method, whereas transforming the text to numerical vectors (using the learnt features) is done by `transform`. Lastly, `fit_transform` does in a single step the learning and transforming process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def obtain_data_representation(df, test=None):\n",
    "    # If there is no test data, split the input\n",
    "    if test is None:\n",
    "        # Divide data in train and test\n",
    "        train, test = train_test_split(df, test_size=0.25)\n",
    "        df.airline_sentiment = pd.Categorical(df.airline_sentiment)\n",
    "    else:\n",
    "        # Otherwise, all is train\n",
    "        train = df\n",
    "    \n",
    "    mylist = ['the', 'a', 'got', 'of', 'is', 'are', 'we', 'you', 'I', 'me', 'them']\n",
    "    # Create a Bag of Words (BoW), by using train data only\n",
    "#    cv = CountVectorizer(max_features=200, stop_words=mylist)\n",
    "    cv = CountVectorizer(analyzer='word', ngram_range=(1,2), token_pattern=r'[^@]\\b\\w+\\b', min_df=1, stop_words='english')\n",
    "\n",
    "    x_train = cv.fit_transform(train['text'])\n",
    "    \n",
    "    y_train = train['airline_sentiment'].values\n",
    "        \n",
    "    #print(cv.vocabulary_)\n",
    "    #print(cv.stop_words_)\n",
    "    \n",
    "    # Obtain BoW for the test data, using the previously fitted one\n",
    "    x_test = cv.transform(test['text'])\n",
    "    try:\n",
    "        y_test = test['airline_sentiment'].values\n",
    "    except:\n",
    "        # It might be the submision file, where we don't have target values\n",
    "        y_test = None\n",
    "        \n",
    "    return {\n",
    "        'train': {\n",
    "            'x': x_train,\n",
    "            'y': y_train\n",
    "        },\n",
    "        'test': {\n",
    "            'x': x_test,\n",
    "            'y': y_test\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Thought this function might seem strange at first, the only thing to know is that training an `sklearn` model is always done the same way:\n",
    "\n",
    "```python\n",
    "# 1. Create the model\n",
    "model = BernoulliNB()\n",
    "\n",
    "# 2. Train with some data, where `x` are features and\n",
    "#    `y` is the target category\n",
    "model.fit(x, y)\n",
    "\n",
    "# 3. Predict new categories for test data (with which we\n",
    "#    have not trained!)\n",
    "y_pred = model.predict(test_x)\n",
    "```\n",
    "\n",
    "We might also obtain the accuracy score by using the function `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_model(dataset, dmodel, *model_args, **model_kwargs):\n",
    "    # Create a Naive Bayes model\n",
    "    model = dmodel(*model_args, **model_kwargs)\n",
    "    \n",
    "    # Train it\n",
    "    model.fit(dataset['train']['x'], dataset['train']['y'])\n",
    "    \n",
    "    # Predict new values for test\n",
    "    y_pred = model.predict(dataset['test']['x'])\n",
    "    \n",
    "    # Print accuracy score unless its the submission dataset\n",
    "    if dataset['test']['y'] is not None:\n",
    "        score = accuracy_score(dataset['test']['y'], y_pred)\n",
    "        print(\"Model score is: {}\".format(score))\n",
    "\n",
    "    # Done\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score is: 0.6347905282331512\n",
      "Model score is: 0.337431693989071\n",
      "Model score is: 0.7786885245901639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pere/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "df = pd.read_csv('tweets_public.csv', index_col='tweet_id')\n",
    "dataset = obtain_data_representation(df)\n",
    "\n",
    "#print(df)\n",
    "#print(dataset['train']['x'])\n",
    "\n",
    "# Train a Bernoulli Naive Bayes\n",
    "modelNB, _ = train_model(dataset, BernoulliNB)\n",
    "\n",
    "# Train a K Nearest Neighbors Classifier\n",
    "modelKN, _ = train_model(dataset, KNeighborsClassifier)\n",
    "\n",
    "modelSGD, _ = train_model(dataset, SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <6588x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 34372 stored elements in Compressed Sparse Row format>,\n",
       " 'y': array(['negative', 'negative', 'negative', ..., 'negative', 'negative',\n",
       "        'neutral'], dtype=object)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit file\n",
    "\n",
    "Once we have found the best model (BernoulliNB for the above simple test), we can train it with all the data (that is, avoid doing a train/test split) and predict sentiments for the real submission data.\n",
    "\n",
    "This cell below performs exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jetblue': 100, 've': 185, 'know': 104, 'seat': 152, '30': 5, 'flying': 77, 'southwestair': 158, 'did': 53, 'dm': 56, 'hold': 88, 'just': 103, 'united': 180, 'flight': 69, 'home': 89, 'united flight': 181, 'lost': 115, 'great': 85, 'website': 193, 'said': 150, 'flights': 74, 'cancelled': 33, 'flighted': 71, 'cancelled flighted': 35, 'late': 105, 'usairways': 183, 'agents': 12, 'late flight': 106, 'm': 118, 'trying': 178, 'missed': 124, 't': 162, '2': 2, 'says': 151, 'number': 131, 'virginamerica': 186, 'http': 95, 'http t': 96, 'time': 169, 'getting': 81, 'flightr': 73, 'll': 113, 'late flightr': 107, 'americanair': 18, 'flightled': 72, 'phone': 137, 'don': 60, 'online': 132, 'flight cancelled': 70, 'cancelled flightled': 36, 'don t': 61, 'connection': 41, 'delays': 51, 'delayed': 50, 'customer': 43, 'service': 155, 'line': 112, 'people': 135, 'customer service': 44, 'got': 84, 'thanks': 165, 'plane': 138, 'airport': 17, 'help': 87, 'crew': 42, 'nice': 129, 'customers': 45, 'worst': 198, 'airline': 15, '6': 8, 'united thanks': 182, '5': 7, 'hour': 92, 'phl': 136, 'min': 121, 'experience': 63, 'hope': 90, 's': 148, 'response': 145, 'able': 10, 'today': 171, 'bag': 22, 'right': 146, 'told': 172, 'seats': 153, 'missing': 125, 'thank': 164, 'like': 111, 'going': 82, 'need': 127, 'tonight': 174, 'amp': 19, 'days': 48, 'gate': 80, 'day': 47, 'free': 79, 'email': 62, 'yes': 199, 'hours': 93, 'bags': 24, 'u': 179, 'travel': 175, 'check': 39, 'miss': 123, 'change': 38, 'work': 196, 'w': 187, 'dfw': 52, 'bad': 21, 'love': 116, 'waiting': 189, '1': 0, 'trip': 177, 'boarding': 27, 'working': 197, 'rude': 147, 'guys': 86, 'airlines': 16, 'best': 25, 'come': 40, 'awesome': 20, 'sitting': 157, 'won': 194, 'minutes': 122, 'won t': 195, 'baggage': 23, 'night': 130, 'air': 14, 'hotel': 91, 'issue': 98, 'staff': 159, 'make': 119, 'tried': 176, 'fly': 76, 'want': 190, 'problems': 140, '10': 1, 'miles': 120, 'better': 26, 'sure': 161, 'tell': 163, 'delay': 49, 'hrs': 94, 'called': 32, 'doesn': 58, 'doesn t': 59, 'use': 184, 'rebook': 142, 'agent': 11, 'd': 46, 'left': 109, 'didn': 54, 'didn t': 55, 'good': 83, '4': 6, 'ago': 13, 'new': 128, 'book': 28, 'let': 110, 'ticket': 167, 'refund': 143, 'flt': 75, 'way': 191, 'wait': 188, 'booking': 30, 'booking problems': 31, 'booked': 29, 'tickets': 168, 'stuck': 160, 'sent': 154, 'reservation': 144, 'luggage': 117, 'lax': 108, 'info': 97, '3': 4, 'aa': 9, 'passengers': 133, 'cancelled flight': 34, '2 hours': 3, 'follow': 78, 'fleet': 67, 'fleek': 65, 'jetblue fleet': 101, 'fleet s': 68, 's fleek': 149, 'fleek http': 66, 'does': 57, 'really': 141, 'tomorrow': 173, 'morning': 126, 'issues': 99, 'care': 37, 'long': 114, 'sfo': 156, 'times': 170, 'think': 166, 'jfk': 102, 'weather': 192, 'pay': 134, 'problem': 139, 'finally': 64}\n",
      "Submission file created: submission_02_01_2018-18_40_54.csv\n",
      "Upload it to Kaggle InClass\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def create_submit_file(df_submission, ypred):\n",
    "    date = datetime.datetime.now().strftime(\"%m_%d_%Y-%H_%M_%S\")\n",
    "    filename = 'submission_' + date + '.csv'\n",
    "    \n",
    "    df_submission['airline_sentiment'] = ypred\n",
    "    df_submission[['airline_sentiment']].to_csv(filename)\n",
    "    \n",
    "    print('Submission file created: {}'.format(filename))\n",
    "    print('Upload it to Kaggle InClass')\n",
    "\n",
    "    \n",
    "# Read submission and retrain with whole data\n",
    "df_submission = pd.read_csv('tweets_submission.csv', index_col='tweet_id')\n",
    "# We use df_submision as test, otherwise it would split df in train/test\n",
    "submission_dataset = obtain_data_representation(df, df_submission)\n",
    "# Predict for df_submission\n",
    "_, y_pred = train_model(submission_dataset, BernoulliNB)\n",
    "\n",
    "# Create submission file with obtained y_pred\n",
    "create_submit_file(df_submission, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569237160886276096</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>venkatesh_cr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue I've been in pricing for 8 years to k...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 12:48:09 -0800</td>\n",
       "      <td>Austin Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569267194028298241</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChristineFlores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir AH - did DM, no reply. On hold n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 14:47:30 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569506670189137920</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>szymanski_t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united if you lost my belongings then BE HONEST!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 06:39:05 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570293957739081728</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nate2482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@United the internet is a great thing.  I am e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:47:29 -0800</td>\n",
       "      <td>Parkersburg, WV</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570212129313316864</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elias_rubin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue I believe that the website said I cou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 05:22:20 -0800</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  569237160886276096          negative                        1.0000   \n",
       "1  569267194028298241          negative                        1.0000   \n",
       "2  569506670189137920          negative                        0.6473   \n",
       "3  570293957739081728          negative                        1.0000   \n",
       "4  570212129313316864           neutral                        1.0000   \n",
       "\n",
       "           negativereason  negativereason_confidence    airline  \\\n",
       "0              Can't Tell                     0.6543      Delta   \n",
       "1  Customer Service Issue                     1.0000  Southwest   \n",
       "2            Lost Luggage                     0.6473     United   \n",
       "3  Customer Service Issue                     1.0000     United   \n",
       "4                     NaN                        NaN      Delta   \n",
       "\n",
       "  airline_sentiment_gold             name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     venkatesh_cr                 NaN              0   \n",
       "1                    NaN  ChristineFlores                 NaN              0   \n",
       "2                    NaN      szymanski_t                 NaN              0   \n",
       "3                    NaN         nate2482                 NaN              0   \n",
       "4                    NaN      elias_rubin                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @JetBlue I've been in pricing for 8 years to k...         NaN   \n",
       "1  @SouthwestAir AH - did DM, no reply. On hold n...         NaN   \n",
       "2  @united if you lost my belongings then BE HONEST!         NaN   \n",
       "3  @United the internet is a great thing.  I am e...         NaN   \n",
       "4  @JetBlue I believe that the website said I cou...         NaN   \n",
       "\n",
       "               tweet_created   tweet_location               user_timezone  \n",
       "0  2015-02-21 12:48:09 -0800     Austin Texas  Central Time (US & Canada)  \n",
       "1  2015-02-21 14:47:30 -0800              NaN  Central Time (US & Canada)  \n",
       "2  2015-02-22 06:39:05 -0800              NaN  Eastern Time (US & Canada)  \n",
       "3  2015-02-24 10:47:29 -0800  Parkersburg, WV  Eastern Time (US & Canada)  \n",
       "4  2015-02-24 05:22:20 -0800     New York, NY  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('tweets_public.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '@': 38, 'u': 178, 's': 160, 'a': 42, 'i': 98, 'r': 152, 'w': 189, 'y': 196, '@u': 41, 'us': 184, 'sa': 162, 'ai': 46, 'ir': 105, 'rw': 159, 'wa': 191, 'ay': 54, 'ys': 199, 'j': 108, 'd': 66, 'b': 55, 'f': 82, 'l': 113, 'e': 71, ' @': 2, 'fl': 84, 'le': 117, 'es': 80, 's ': 161, \"'\": 26, ' w': 21, 'we': 192, 're': 155, 'e ': 72, 'x': 195, 'c': 60, 't': 167, ' e': 7, 'it': 107, 'te': 172, 'ed': 75, 'd ': 67, 'o': 139, ' t': 19, 'to': 175, 'o ': 140, 'h': 90, 'v': 186, ' h': 10, 'ha': 92, 'av': 53, 've': 187, ' y': 22, 'yo': 198, 'ou': 147, 'u ': 179, ' f': 8, 'ly': 122, 'y ': 197, 'wi': 194, 'th': 173, 'h ': 91, ',': 27, ' u': 20, ', ': 28, '!': 23, '! ': 24, 'n': 129, 'wh': 193, 'he': 93, 'en': 78, 'n ': 130, 'il': 102, 'll': 119, 'l ': 114, 'hi': 94, 'is': 106, '?': 36, ' b': 4, 'be': 57, 'p': 149, 'g': 86, ' s': 18, 'ri': 156, 'in': 103, 'ng': 135, 'g ': 87, 'k': 110, 'ea': 73, 'k ': 111, 'm': 123, '@a': 39, 'am': 48, 'me': 126, 'er': 79, 'ic': 100, 'ca': 61, 'an': 49, 'na': 131, 'r ': 153, '.': 29, '. ': 30, ' p': 16, 'oo': 144, 'or': 145, 'pl': 151, 'la': 115, 'ni': 136, ' o': 15, 'on': 143, ' m': 13, 'my': 128, 'ar': 50, 't.': 169, ' i': 11, 'i ': 99, ' a': 3, 'as': 51, 'ss': 165, ' c': 5, 'bo': 59, 't ': 168, '? ': 37, 'ho': 95, 'ow': 148, 'w ': 190, 'lu': 121, 'ue': 180, 'el': 77, 'ee': 76, 'ti': 174, 'fo': 85, '2': 35, 'ut': 185, 'a ': 43, ' r': 17, 'un': 182, 'nd': 133, 'ro': 157, 'om': 142, 'm ': 124, 'nc': 132, 'ce': 62, 'li': 118, 'ig': 101, 'gh': 89, 'ht': 96, 'ld': 116, ' n': 14, 'no': 137, '1': 34, 'mi': 127, 'ck': 64, 'st': 166, 'of': 141, 'f ': 83, 'bl': 58, 'at': 52, 'io': 104, 'nt': 138, 'ad': 44, 'se': 163, 'ul': 181, 'je': 109, 'et': 81, 'tb': 171, 'co': 65, 'ma': 125, 'ot': 146, 'vi': 188, 'di': 69, 'ne': 134, '@s': 40, 'so': 164, 'hw': 97, 'ta': 170, ' d': 6, 'do': 70, 'pe': 150, 'ec': 74, 'al': 47, 'de': 68, 'ch': 63, ' g': 9, 'ra': 154, ' l': 12, '#': 25, ' #': 1, 'ag': 45, 'rs': 158, 'ur': 183, 'ba': 56, 'tr': 176, 'lo': 120, '0': 33, 'tt': 177, 'ke': 112, '/': 32, 'ge': 88, '..': 31}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_public.csv', index_col='tweet_id')\n",
    "dataset = obtain_data_representation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'x': <2196x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 181830 stored elements in Compressed Sparse Row format>,\n",
       "  'y': array(['negative', 'negative', 'negative', ..., 'negative', 'negative',\n",
       "         'negative'], dtype=object)},\n",
       " 'train': {'x': <6588x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 545952 stored elements in Compressed Sparse Row format>,\n",
       "  'y': array(['positive', 'neutral', 'negative', ..., 'negative', 'neutral',\n",
       "         'negative'], dtype=object)}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>569088825420607488</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTFloris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways Got it, thanks!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 02:58:43 -0800</td>\n",
       "      <td>Raxacoricofallapatorius</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>567773445195583488</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MatthewJLeBlanc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir Thanks for the response. Was abl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 11:51:52 -0800</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>567847753277120512</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dudleywright</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united thanks for not getting my BusinessFirs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 16:47:09 -0800</td>\n",
       "      <td>Johnstown, Ohio</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>569891440135794688</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heatherjpitcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Thank You! CC: @packermama1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 08:08:02 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>567775418612195328</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColtSTaylor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united looks like I'm settled in to where I'm...</td>\n",
       "      <td>[39.85871934, -104.67371484]</td>\n",
       "      <td>2015-02-17 11:59:43 -0800</td>\n",
       "      <td>All Over The World</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "14  569088825420607488          positive                        1.0000   \n",
       "21  567773445195583488          positive                        1.0000   \n",
       "22  567847753277120512          positive                        1.0000   \n",
       "28  569891440135794688          positive                        1.0000   \n",
       "29  567775418612195328          positive                        0.6522   \n",
       "\n",
       "   negativereason  negativereason_confidence     airline  \\\n",
       "14            NaN                        NaN  US Airways   \n",
       "21            NaN                        NaN   Southwest   \n",
       "22            NaN                        NaN      United   \n",
       "28            NaN                        NaN    American   \n",
       "29            NaN                        NaN      United   \n",
       "\n",
       "   airline_sentiment_gold             name negativereason_gold  retweet_count  \\\n",
       "14                    NaN         WTFloris                 NaN              0   \n",
       "21                    NaN  MatthewJLeBlanc                 NaN              0   \n",
       "22                    NaN     dudleywright                 NaN              0   \n",
       "28                    NaN  heatherjpitcher                 NaN              0   \n",
       "29                    NaN      ColtSTaylor                 NaN              0   \n",
       "\n",
       "                                                 text  \\\n",
       "14                         @USAirways Got it, thanks!   \n",
       "21  @SouthwestAir Thanks for the response. Was abl...   \n",
       "22  @united thanks for not getting my BusinessFirs...   \n",
       "28           @AmericanAir Thank You! CC: @packermama1   \n",
       "29  @united looks like I'm settled in to where I'm...   \n",
       "\n",
       "                     tweet_coord              tweet_created  \\\n",
       "14                           NaN  2015-02-21 02:58:43 -0800   \n",
       "21                           NaN  2015-02-17 11:51:52 -0800   \n",
       "22                           NaN  2015-02-17 16:47:09 -0800   \n",
       "28                           NaN  2015-02-23 08:08:02 -0800   \n",
       "29  [39.85871934, -104.67371484]  2015-02-17 11:59:43 -0800   \n",
       "\n",
       "             tweet_location               user_timezone  \n",
       "14  Raxacoricofallapatorius                   Amsterdam  \n",
       "21            Nashville, TN  Central Time (US & Canada)  \n",
       "22          Johnstown, Ohio                       Quito  \n",
       "28                      NaN                       Quito  \n",
       "29       All Over The World                         NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp = dataset[dataset['airline_sentiment'] == 'positive']\n",
    "gn = dataset[dataset['airline_sentiment'] == 'negative']\n",
    "\n",
    "gp.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
