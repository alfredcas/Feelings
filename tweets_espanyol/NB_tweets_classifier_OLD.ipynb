{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/pere/anaconda3/lib/python3.6/site-packages/scipy/sparse/_sparsetools.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libc++abi.1.dylib\n  Referenced from: /Users/pere/anaconda3/lib/libc++.1.dylib\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eeb00bd46896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[0;31m# avoid flakes unused variable error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sparsetools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_tocsc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_tobsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_count_blocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mget_csr_submatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_sample_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m from .sputils import (upcast, isintlike, IndexMixin, issequence,\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/pere/anaconda3/lib/python3.6/site-packages/scipy/sparse/_sparsetools.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libc++abi.1.dylib\n  Referenced from: /Users/pere/anaconda3/lib/libc++.1.dylib\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_file(df_submission, ypred):\n",
    "    date = datetime.datetime.now().strftime(\"%m_%d_%Y-%H_%M_%S\")\n",
    "    filename = 'submission_' + date + '.csv'\n",
    "\n",
    "    df_submission['airline_sentiment'] = ypred\n",
    "    df_submission[['airline_sentiment']].to_csv(filename)\n",
    "\n",
    "    print('Submission file created: {}'.format(filename))\n",
    "    print('Upload it to Kaggle InClass')\n",
    "\n",
    "def stemlematizer(df):\n",
    "    \"\"\" Function to reduce the words to their root\n",
    "    \"\"\"\n",
    "    lemmer=WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "    new_corpus1 = [' '.join([stemmer.stem(word) for word in tweet.split(' ')]) for tweet in df.text.values]\n",
    "    new_corpus = [' '.join([lemmer.lemmatize(word) for word in tweet.split(' ')]) for tweet in new_corpus1] \n",
    "    \n",
    "    df.text = new_corpus\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def load_and_train(dataframe, trainmodelclassifier, test=None, *model_args, **model_kwargs ):\n",
    "\n",
    "# If there is no test data, split the input\n",
    "    if test is None:\n",
    "        train, test = train_test_split(dataframe, test_size=0.15)\n",
    "    else:\n",
    "        train = dataframe\n",
    "\n",
    "    dataframe.airline_sentiment = pd.Categorical(dataframe.airline_sentiment)\n",
    "    \n",
    "    x_train = train['text']\n",
    "    y_train = train['airline_sentiment']\n",
    "    \n",
    "    x_test = test['text']\n",
    "    #we create the list of stop words specific for spanish:\n",
    "    spanish_stop_words = stopwords.words('spanish')\n",
    "    #we build the classifier, that has everything inside:\n",
    "    text_clf = Pipeline([('vect', CountVectorizer(min_df=1,\n",
    "                                              stop_words=spanish_stop_words, ngram_range=(1,2), \n",
    "                                              analyzer='word', token_pattern=r'[^@]\\b\\w+\\b')),\n",
    "                     ('tfidf', TfidfTransformer(norm='l2')),\n",
    "                     ('clf', trainmodelclassifier(*model_args, **model_kwargs))])\n",
    "\n",
    "    \n",
    "\n",
    "# SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None))])\n",
    "\n",
    "    text_clf.fit(x_train, y_train)\n",
    "    predicted = text_clf.predict(x_test)\n",
    "\n",
    "    try:\n",
    "        y_test = test['airline_sentiment'].values\n",
    "    except:\n",
    "        # It might be the submision file, where we don't have target values\n",
    "        y_test = None\n",
    "   \n",
    "    try:\n",
    "        acc = accuracy_score(test.airline_sentiment, predicted)\n",
    "        print('accuracy_score = ', acc)\n",
    "    except:\n",
    "        print('No accuracy computed beacuse there is NO test target')\n",
    "        acc = None\n",
    "    return predicted, x_train, y_train, x_test, y_test, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_public.csv', encoding='utf-16', index_col='tweet_id')\n",
    "df_submission = pd.read_csv('tweets_submission.csv', index_col='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stemlematizer(df)\n",
    "df_submission = stemlematizer(df_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id\n",
       "942743012337123328    \"los pilot de ryan desconvoc la huelg tras ver...\n",
       "926857871916183553    @iberi @lavecinarubi si ,por favor la declar d...\n",
       "936979305720090626              @iberi me dir por favor que cost tiene?\n",
       "943983853802328064    @supermanlopezn @iberi @giroditali champion, n...\n",
       "938207464457211904    @srtafarrelldm @klm @iberi eso de avianc e ver...\n",
       "931526746301714435    @iberi hola, no conozc mi numer iberi plus, el...\n",
       "933385784228532233    el canal smithsoni reconstru en vide el accide...\n",
       "932856751099142144    con @iberia, mi destin a un sol click. ¡desead...\n",
       "927623530585509889    @facu pued ayud con una malet perd por iberia?...\n",
       "930719355704430592    rt @muchachino: en el sistem de entreten de @i...\n",
       "938115911084593153    men mal que no soy @paugasol @iberia... mejor ...\n",
       "944883680970969088    amig de @iberi menud impresentables, despu de ...\n",
       "937549230994051073    con @iberia, mi destin a un sol click. ¡desead...\n",
       "941081978807431169    marian diez, director de marketing de quilosa-...\n",
       "933352064910012416        @iberi a350!? los van a usar en la rut a eze?\n",
       "941598213106229248    ryan reconoc a los sindicat por primer vez en ...\n",
       "923921122495787008    se habl de la lech que se esta peg el sabadell...\n",
       "931611760829792256    con @iberia, mi destin a un sol click. ¡desead...\n",
       "943844779976208384    ofert de #emple #tcp: @iberi busc auxiliar de ...\n",
       "941121849366368258    iberi ampli ofert de asient a mexico, argentin...\n",
       "942150441445548032    iberi plus cumpl 25 años. quer celebr contig d...\n",
       "941436315547127809            @iberi @tiburonsanz a ver com llega......\n",
       "930553946023841794    @toppertorp pues siend una, digamos, filial de...\n",
       "937424103488843776    @iberi no te preocup @iberi esper a que me toq...\n",
       "923271099151994880    @iberi si. ya me hab ido. no hab ningun stand ...\n",
       "941368109289693186    iberi celebr su 90 aniversario: casi un sigl v...\n",
       "942400199523295233    cosm k - ryan @ochoymedioclub 15/12/2017: http...\n",
       "938270102583001088    \"pued encontr tiemp par la tecnolog y tambien ...\n",
       "940735482958401536    iberi plus cumpl 25 años. quer celebr contig d...\n",
       "933098303306076161    con @iberia, mi destin a un sol click. ¡desead...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.543607112616\n"
     ]
    }
   ],
   "source": [
    "# Using a SGDClassifier: it fits a linear support vector machine (SVM) \n",
    "predicted, x_train, y_train, x_test, y_test, acc = load_and_train(df, SGDClassifier, test=None, penalty='elasticnet', max_iter=10)\n",
    "#create_submit_file(df_submission, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.521591871296\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEKCAYAAAB0cRxpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5XCiNDPL8f8BlDB8OOU2lCEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156920f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.53      0.93      0.68       570\n",
      "    neutral       0.50      0.17      0.26       390\n",
      "   positive       0.37      0.08      0.13       221\n",
      "\n",
      "avg / total       0.49      0.52      0.44      1181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(y, y_pred):\n",
    "    plt.imshow(metrics.confusion_matrix(y, y_pred),\n",
    "               cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('true value')\n",
    "    plt.xlabel('predicted value')\n",
    "    plt.show()\n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "plot_confusion_matrix(y_test, predicted)\n",
    "print(metrics.classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to try to improve the training by searching which training subset gives best score (since each training subset is selected randomly). Just for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  0.578323454699\n",
      "accuracy_score =  0.537679932261\n",
      "accuracy_score =  0.562235393734\n",
      "accuracy_score =  0.552074513124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5cb513c043fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elasticnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-088e1a9080f1>\u001b[0m in \u001b[0;36mload_and_train\u001b[0;34m(dataframe, trainmodelclassifier, test, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m# disable defaultdict behaviour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    predicted, x_train, y_train, x_test, y_test, acc = load_and_train(df, SGDClassifier, test=None, penalty='elasticnet', max_iter=10)\n",
    "    if acc > 0.8:\n",
    "        print(acc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission_05_30_2018-11_52_35.csv\n",
      "Upload it to Kaggle InClass\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(min_df=1,\n",
    "                                              stop_words=spanish_stop_words, ngram_range=(1,2), \n",
    "                                              analyzer='word', token_pattern=r'[^@]\\b\\w+\\b')),\n",
    "                     ('tfidf', TfidfTransformer(norm='l2')),\n",
    "                     ('clf', SGDClassifier(penalty='elasticnet', max_iter=10))])\n",
    "\n",
    "x_test = df_submission['text']\n",
    "text_clf.fit(x_train, y_train)\n",
    "predicted = text_clf.predict(x_test)\n",
    "\n",
    "create_submit_file(df_submission, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created this function to load the data in a dictionary form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "def load_and_divide(dataframe, test=None):\n",
    "\n",
    "# If there is no test data, split the input\n",
    "    if test is None:\n",
    "        train, test = train_test_split(dataframe, test_size=0.15)\n",
    "    else:\n",
    "        train = dataframe\n",
    "\n",
    "    dataframe.airline_sentiment = pd.Categorical(dataframe.airline_sentiment)\n",
    "    \n",
    "    x_train = train['text']\n",
    "    y_train = train['airline_sentiment']\n",
    "    \n",
    "    x_test = test['text']\n",
    "    \n",
    "    try:\n",
    "        y_test = test['airline_sentiment']\n",
    "    except:\n",
    "        # It might be the submision file, where we don't have target values\n",
    "        y_test = None\n",
    "        \n",
    "    return {\n",
    "        'train': {\n",
    "            'x': x_train,\n",
    "            'y': y_train\n",
    "        },\n",
    "        'test': {\n",
    "            'x': x_test,\n",
    "            'y': y_test\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_and_divide(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried this example from the DataCleaning notebook, using textblob, but the overall accuracy is not better than the other approach that I used, and the process is extremely slower that the other. **Discarded for the moment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for i in np.arange(len(data['train']['x'])):\n",
    "    data_tuple = (data['train']['x'].iloc[i], data['train']['y'].iloc[i])\n",
    "    dataset_list.append(data_tuple)\n",
    "\n",
    "dataset_test_list = []\n",
    "for i in np.arange(len(data['test']['x'])):\n",
    "    data_tuple = (data['test']['x'].iloc[i], data['test']['y'].iloc[i])\n",
    "    dataset_test_list.append(data_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050075872534143"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(dataset_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'airline_sentiment_confidence', 'negativereason',\n",
       "       'negativereason_confidence', 'airline', 'airline_sentiment_gold',\n",
       "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
       "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords = df['tweet_coord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id\n",
       "569237160886276096                             NaN\n",
       "569267194028298241                             NaN\n",
       "569506670189137920                             NaN\n",
       "570293957739081728                             NaN\n",
       "570212129313316864                             NaN\n",
       "570021485466685440                             NaN\n",
       "568894795294363648                             NaN\n",
       "568833739192557569                             NaN\n",
       "568603024320434176                             NaN\n",
       "569645815268044801                             NaN\n",
       "569469326547222528                             NaN\n",
       "569604033083789312                             NaN\n",
       "568807928154558464                             NaN\n",
       "569906446881697793                             NaN\n",
       "569088825420607488                             NaN\n",
       "570023318251642883                             NaN\n",
       "569839377104285696                             NaN\n",
       "569301668904329216                             NaN\n",
       "568855468975759360                             NaN\n",
       "568595632140775424                             NaN\n",
       "567761297879646208                             NaN\n",
       "567773445195583488                             NaN\n",
       "567847753277120512                             NaN\n",
       "569890651107491840                             NaN\n",
       "569641319712169984                             NaN\n",
       "569493640990625793                             NaN\n",
       "569875456415170560                             NaN\n",
       "569380081254027265                             NaN\n",
       "569891440135794688                             NaN\n",
       "567775418612195328    [39.85871934, -104.67371484]\n",
       "                                  ...             \n",
       "569002132621398016                             NaN\n",
       "569562990250323968                             NaN\n",
       "569971526876962819                             NaN\n",
       "569977974176378880                             NaN\n",
       "568053414682361856                             NaN\n",
       "569518412550033408                             NaN\n",
       "569879497891303424                             NaN\n",
       "568451040397422593                             NaN\n",
       "570263872004874240                             NaN\n",
       "567812709342822400                             NaN\n",
       "570259388872695808                             NaN\n",
       "568909605499215872                             NaN\n",
       "570143097809707008                             NaN\n",
       "568863902106320896                             NaN\n",
       "568606101412962304                             NaN\n",
       "569895932394917888                             NaN\n",
       "568443923485437952                             NaN\n",
       "568814251311288320                             NaN\n",
       "567816651900583936                             NaN\n",
       "569945910546989057                             NaN\n",
       "570009897846374400                             NaN\n",
       "569738487269756928                             NaN\n",
       "568104424029036545                             NaN\n",
       "568535405361913857                             NaN\n",
       "569940226984042496                             NaN\n",
       "568616034384498688     [40.64719984, -73.77530956]\n",
       "569379997175177216      [43.74167873, -79.3442243]\n",
       "568970344154836993                             NaN\n",
       "568912677994696706                             NaN\n",
       "570042533679656960                             NaN\n",
       "Name: tweet_coord, Length: 8784, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords = df_coords.dropna(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = [], []\n",
    "for i in np.arange(len(df_coords)):\n",
    "    ln, lt = literal_eval(df_coords[i])\n",
    "    lat.append(lt)\n",
    "    lon.append(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ANAIP4Pi/LsavLqAOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c038f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(lat, lon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, GMapOptions\n",
    "from bokeh.plotting import gmap\n",
    "\n",
    "\n",
    "map_options = GMapOptions(lat=40., lng=-100., map_type=\"roadmap\", zoom=1)\n",
    "p = gmap(\"AIzaSyDoOj415ZjLvtoltW7gYhS8x7eszVzHGjw\", map_options, title=\"Austin\")\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(lat=lon,\n",
    "              lon=lat)\n",
    ")\n",
    "\n",
    "p.circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"blue\", fill_alpha=0.4, source=source)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
